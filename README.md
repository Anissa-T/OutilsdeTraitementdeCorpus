# ğŸŒ» Outils de Traitement de Corpus ğŸŒ» 
Anissa Thezenas ğŸ‘©ğŸ¾â€ğŸ’»

1. Je souhaites rÃ©aliser la tÃ¢che suivante : Natural Language Processing : Summarization  ğŸ“„
2. un corpus qui rÃ©pond Ã  cette tÃ¢che : link ğŸ”— : https://huggingface.co/datasets/databricks/databricks-dolly-15k
3. Ã  quel type de prÃ©diction peut servir ce corpus : ce corpus peut servir Ã  faire des rÃ©sumers de textes plus ou moins long, permettre Ã  un model de faire des paraphrases. Extraction d'informations, 
4. Ã  quel modÃ¨le il a servi : databricks/dolly-v2-3b ou encore TheBloke/Mythalion-13B-AWQ ğŸ¤–
5. Apprenez moi des choses sur un corpus :  le corpus se nomme Dolly comme le premier mouton clonÃ© ? ğŸ‘ De plus le corpus est composÃ© de 15 011 lignes 

Ajustements : Le dataset Databricks Dolly 15k est une collection conÃ§ue spÃ©cialement pour le rÃ©glage des instructions des grands modÃ¨les de langage. Il comprend plus de 15 000 paires de consignes et rÃ©ponses gÃ©nÃ©rÃ©es par plus de 5 000 employÃ©s de Databricks pendant les mois de mars et avril 2023. Ce dataset vise Ã  dÃ©velopper des modÃ¨les capables d'imiter les capacitÃ©s conversationnelles de systÃ¨mes comme ChatGPT.

Ce dataset couvre diverses catÃ©gories comportementales telles que dÃ©finies dans le document InstructGPT, incluant le brainstorming, la classification, les questions-rÃ©ponses fermÃ©es (QA), la gÃ©nÃ©ration, l'extraction d'informations, les questions-rÃ©ponses ouvertes, et la rÃ©sumÃ©. Les contributeurs, tous employÃ©s de Databricks, ont Ã©tÃ© guidÃ©s pour crÃ©er ces paires sans utiliser d'informations provenant du web, Ã  l'exception de WikipÃ©dia pour certaines tÃ¢ches spÃ©cifiques, et il leur a Ã©tÃ© recommandÃ© de ne pas utiliser d'IA gÃ©nÃ©rative pour formuler les contenus, garantissant ainsi que les rÃ©ponses sont vÃ©ritablement gÃ©nÃ©rÃ©es par des humains.

Le dataset Databricks Dolly 15k est open source, disponible sous la licence Creative Commons Attribution-ShareAlike 3.0 Unported, ce qui permet son utilisation Ã  des fins acadÃ©miques et commerciales. Cela inclut des tÃ¢ches telles que la formation de modÃ¨les de langage, la gÃ©nÃ©ration de donnÃ©es synthÃ©tiques et l'augmentation de donnÃ©es.