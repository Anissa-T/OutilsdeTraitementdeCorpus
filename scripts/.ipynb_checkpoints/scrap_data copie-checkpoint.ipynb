{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06bc983e-53b2-4ed8-8bd8-58d2702f2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3111e56a-d532-47c5-9107-d50bac19fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_urls(chemin_fichier):\n",
    "    \"\"\"Lire les URLs à partir d'un fichier texte.\n",
    "\n",
    "    Args:\n",
    "        chemin_fichier (str): Le chemin d'accès au fichier texte contenant les URLs.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste d'URLs.\n",
    "    \"\"\"\n",
    "    with open(chemin_fichier, 'r') as fichier:\n",
    "        return [ligne.strip() for ligne in fichier if ligne.strip()]\n",
    "\n",
    "def extraire_article(url):\n",
    "    \"\"\"Extraire le titre et le contenu d'un article complet, en excluant la description.\n",
    "\n",
    "    Args:\n",
    "        url (str): L'URL de la page web à scraper.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant l'ID (URL), le titre et le contenu de l'article, ainsi que la description.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        en_tetes = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        reponse = requests.get(url, headers=en_tetes)\n",
    "        reponse.raise_for_status()\n",
    "\n",
    "        soupe = BeautifulSoup(reponse.text, 'html.parser')\n",
    "\n",
    "        # Trouver le titre\n",
    "        balise_titre = soupe.find('title')\n",
    "        titre = balise_titre.get_text(strip=True) if balise_titre else 'Titre non trouvé'\n",
    "\n",
    "        # Trouver le contenu de l'article, en excluant la description\n",
    "        balise_article = soupe.find('article')\n",
    "        if balise_article:\n",
    "            # Supprimer les éventuelles balises de description du contenu de l'article\n",
    "            for meta in balise_article.find_all('meta', attrs={'name': 'description'}):\n",
    "                meta.decompose()\n",
    "\n",
    "            # Récupérer tous les paragraphes et les balises d'en-tête dans la balise article\n",
    "            contenu = '\\n'.join([p.get_text(strip=True) for p in balise_article.find_all(['p', 'h2', 'h3', 'h4'])])\n",
    "        else:\n",
    "            contenu = \"Contenu de l'article non trouvé\"\n",
    "\n",
    "        # Extraire la description séparément\n",
    "        balise_description = soupe.find('meta', attrs={'name': 'description'})\n",
    "        description = balise_description['content'] if balise_description else 'Aucune description trouvée'\n",
    "\n",
    "        return {\"id\": url, \"titre\": titre, \"contenu\": contenu, \"description\": description}\n",
    "    except Exception as e:\n",
    "        print(f\"Échec du scraping de {url} : {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def ecrire_dans_csv(donnees, fichier_csv):\n",
    "    \"\"\"Écrire une liste de dictionnaires dans un fichier CSV avec des colonnes spécifiques.\n",
    "\n",
    "    Args:\n",
    "        donnees (list): Une liste de dictionnaires contenant les données à écrire dans le fichier CSV.\n",
    "        fichier_csv (str): Le nom du fichier CSV dans lequel écrire les données.\n",
    "    \"\"\"\n",
    "    repertoire_sortie = 'output_data'\n",
    "    if not os.path.exists(repertoire_sortie):\n",
    "        os.makedirs(repertoire_sortie)\n",
    "\n",
    "    with open(os.path.join(repertoire_sortie, fichier_csv), 'w', newline='', encoding='utf-8') as fichier:\n",
    "        noms_colonnes = [\"id\", \"titre\", \"contenu\", \"description\"]\n",
    "        ecrivain = csv.DictWriter(fichier, fieldnames=noms_colonnes)\n",
    "        ecrivain.writeheader()\n",
    "        ecrivain.writerows(donnees)\n",
    "\n",
    "def principal():\n",
    "    \"\"\"Fonction principale pour scraper les articles et enregistrer les données dans un fichier CSV.\"\"\"\n",
    "    chemin_fichier = '../data/url_leparisien.txt'\n",
    "    fichier_csv = 'scraped_data.csv'\n",
    "\n",
    "    urls = lire_urls(chemin_fichier)\n",
    "    articles = []\n",
    "\n",
    "    for url in urls:\n",
    "        article = extraire_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    ecrire_dans_csv(articles, fichier_csv)\n",
    "\n",
    "    # Lire le fichier CSV dans un DataFrame Pandas et afficher les résultats\n",
    "    dataframe = pd.read_csv(os.path.join('output_data', fichier_csv))\n",
    "    print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776ab7d6-fe24-485b-9799-c43d1d80ad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   id  \\\n",
      "0   https://www.leparisien.fr/jo-paris-2024/tennis...   \n",
      "1   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "2   https://www.leparisien.fr/sports/pour-le-kyks-...   \n",
      "3   https://www.leparisien.fr/jo-paris-2024/tennis...   \n",
      "4   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "5   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "6   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "7   https://www.leparisien.fr/jo-paris-2024/le-rel...   \n",
      "8   https://www.leparisien.fr/jo-paris-2024/il-sag...   \n",
      "9   https://www.leparisien.fr/essonne-91/les-ulis-...   \n",
      "10  https://www.leparisien.fr/essonne-91/les-ulis-...   \n",
      "11  https://www.leparisien.fr/economie/un-habitant...   \n",
      "12  https://www.leparisien.fr/culture-loisirs/tv/u...   \n",
      "13  https://www.leparisien.fr/international/cent-m...   \n",
      "14  https://www.leparisien.fr/faits-divers/tel-un-...   \n",
      "15  https://www.leparisien.fr/sports/cyclisme/giro...   \n",
      "16  https://www.leparisien.fr/paris-75/europeennes...   \n",
      "17  https://www.leparisien.fr/meteo/pourquoi-il-a-...   \n",
      "\n",
      "                                                titre  \\\n",
      "0   JO Paris 2024 : les pongistes Alexis Lebrun et...   \n",
      "1   JO Paris 2024 : Marchand, Mayer, Mossely, Rine...   \n",
      "2   « Pour le Kyks » : l’inattendue célébration du...   \n",
      "3   JO Paris 2024 : « Deux champions qui n’ont pas...   \n",
      "4   JO Paris 2024 : « On peut être une drag-queen ...   \n",
      "5   JO Paris 2024 : Thomas Pesquet portera la flam...   \n",
      "6   JO Paris 2024 : un tournoi de qualification « ...   \n",
      "7   JO Paris 2024 : le relais de la flamme a début...   \n",
      "8   « Il s’agit de créer des liens avec les gens »...   \n",
      "9   Les Ulis : un forain de 15 ans grièvement bles...   \n",
      "10  Les Ulis : une femme de 100 ans hospitalisée a...   \n",
      "11  Un habitant sur 74 est millionnaire à Paris et...   \n",
      "12  « Une heureuse nouvelle » : Sonia Mabrouk anno...   \n",
      "13  Cent morts, retour de la pluie… Ce que l’on sa...   \n",
      "14  « Tel un Christophe Colomb » : Stéphane Plaza ...   \n",
      "15  Giro 2024 : frustration pour Julian Alaphilipp...   \n",
      "16  Européennes : à Paris, l’Arc de Triomphe illum...   \n",
      "17  Pourquoi il a fait plus froid et moins beau qu...   \n",
      "\n",
      "                                              contenu  \\\n",
      "0   La fédération internationale de tennis de tabl...   \n",
      "1   Entre stages d’entraînement et compétitions, l...   \n",
      "2   Vainqueur pour la première fois de sa carrière...   \n",
      "3   Félix et Alexis Lebrun étaient de passage ce j...   \n",
      "4   Martin Namias, connu sous son nom de drag-quee...   \n",
      "5   La flamme olympique traversera Le Mont-Saint-M...   \n",
      "6   L’équipe de France, composée de douze lutteurs...   \n",
      "7   L’ex-international français, seul buteur lors ...   \n",
      "8   Ce jeudi 9 mai, c’est le début du relais de la...   \n",
      "9   L’accident s’est produit vers 18h30, samedi, s...   \n",
      "10  Une enquête a été ouverte après l’agression, l...   \n",
      "11  Près de 165 000 millionnaires résident à Paris...   \n",
      "12  La présentatrice a annoncé ce jeudi 9 mai qu’e...   \n",
      "13  La situation, déjà critique dans l’État du Rio...   \n",
      "14  L’animateur et agent immobilier s’était compar...   \n",
      "15  Le Français, dans le groupe de tête jusqu’au b...   \n",
      "16  À l’occasion de la Journée de l’Europe, plusie...   \n",
      "17  Le thermomètre est resté sous les 15°C dans ce...   \n",
      "\n",
      "                                          description  \n",
      "0   La fédération internationale de tennis de tabl...  \n",
      "1   Entre stages d’entraînement et compétitions, l...  \n",
      "2   Vainqueur pour la première fois de sa carrière...  \n",
      "3   Félix et Alexis Lebrun étaient de passage ce j...  \n",
      "4   Martin Namias, connu sous son nom de drag-quee...  \n",
      "5   La flamme olympique traversera Le Mont-Saint-M...  \n",
      "6   L’équipe de France, composée de douze lutteurs...  \n",
      "7   L’ex-international français, seul buteur lors ...  \n",
      "8   Ce jeudi 9 mai, c’est le début du relais de la...  \n",
      "9   L’accident s’est produit vers 18h30, samedi, s...  \n",
      "10  Une enquête a été ouverte après l’agression, l...  \n",
      "11  Près de 165 000 millionnaires résident à Paris...  \n",
      "12  La présentatrice a annoncé ce jeudi 9 mai qu’e...  \n",
      "13  La situation, déjà critique dans l’État du Rio...  \n",
      "14  L’animateur et agent immobilier s’était compar...  \n",
      "15  Le Français, dans le groupe de tête jusqu’au b...  \n",
      "16  À l’occasion de la Journée de l’Europe, plusie...  \n",
      "17  Le thermomètre est resté sous les 15°C dans ce...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    principal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659da42-b2be-46a0-bf6d-84425d093725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e7fbb-bffb-4eca-bf8d-e3df665f51d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
