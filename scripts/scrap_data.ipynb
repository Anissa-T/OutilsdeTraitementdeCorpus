{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bc983e-53b2-4ed8-8bd8-58d2702f2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3111e56a-d532-47c5-9107-d50bac19fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_urls(file_path):\n",
    "    \"\"\"Read URLs from a text file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file if line.strip()]\n",
    "\n",
    "def scrape_article(url):\n",
    "    \"\"\"Scrape title and content into a full article, excluding the description.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the title\n",
    "        title_tag = soup.find('title')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Title not found'\n",
    "\n",
    "        # Find the article content, excluding the description\n",
    "        article_tag = soup.find('article')\n",
    "        if article_tag:\n",
    "            # Remove potential description elements from the article content\n",
    "            for meta in article_tag.find_all('meta', attrs={'name': 'description'}):\n",
    "                meta.decompose()\n",
    "\n",
    "            # Collect all paragraphs and header tags within the article tag\n",
    "            content = '\\n'.join([p.get_text(strip=True) for p in article_tag.find_all(['p', 'h2', 'h3', 'h4'])])\n",
    "        else:\n",
    "            content = 'Article content not found'\n",
    "\n",
    "        # Combine title and content into one full article\n",
    "        full_article = f\"{title}\\n\\n{content}\"\n",
    "\n",
    "        # Extract the description separately\n",
    "        description_tag = soup.find('meta', attrs={'name': 'description'})\n",
    "        description = description_tag['content'] if description_tag else 'No description found'\n",
    "\n",
    "        return {\"id\": url, \"article\": full_article, \"description\": description}\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def write_to_csv(data, csv_file):\n",
    "    \"\"\"Write the list of dictionaries to a CSV file with specific columns.\"\"\"\n",
    "    output_dir = 'output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(os.path.join(output_dir, csv_file), 'w', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = [\"id\", \"article\", \"description\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to scrape articles and save data in a CSV file.\"\"\"\n",
    "    file_path = '../data/url_leparisien.txt'\n",
    "    csv_file = 'scraped_data.csv'\n",
    "\n",
    "    urls = read_urls(file_path)\n",
    "    articles = []\n",
    "\n",
    "    for url in urls:\n",
    "        article = scrape_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    write_to_csv(articles, csv_file)\n",
    "\n",
    "    # Read the CSV file into a Pandas DataFrame and display the results\n",
    "    df = pd.read_csv(os.path.join('output_data', csv_file))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776ab7d6-fe24-485b-9799-c43d1d80ad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   id  \\\n",
      "0   https://www.leparisien.fr/jo-paris-2024/tennis...   \n",
      "1   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "2   https://www.leparisien.fr/sports/pour-le-kyks-...   \n",
      "3   https://www.leparisien.fr/jo-paris-2024/tennis...   \n",
      "4   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "5   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "6   https://www.leparisien.fr/jo-paris-2024/jo-par...   \n",
      "7   https://www.leparisien.fr/jo-paris-2024/le-rel...   \n",
      "8   https://www.leparisien.fr/jo-paris-2024/il-sag...   \n",
      "9   https://www.leparisien.fr/essonne-91/les-ulis-...   \n",
      "10  https://www.leparisien.fr/essonne-91/les-ulis-...   \n",
      "\n",
      "                                              article  \\\n",
      "0   JO Paris 2024 : les pongistes Alexis Lebrun et...   \n",
      "1   JO Paris 2024 : Marchand, Mayer, Mossely, Rine...   \n",
      "2   « Pour le Kyks » : l’inattendue célébration du...   \n",
      "3   JO Paris 2024 : « Deux champions qui n’ont pas...   \n",
      "4   JO Paris 2024 : « On peut être une drag-queen ...   \n",
      "5   JO Paris 2024 : Thomas Pesquet portera la flam...   \n",
      "6   JO Paris 2024 : un tournoi de qualification « ...   \n",
      "7   JO Paris 2024 : le relais de la flamme a début...   \n",
      "8   « Il s’agit de créer des liens avec les gens »...   \n",
      "9   Les Ulis : un forain de 15 ans grièvement bles...   \n",
      "10  Les Ulis : une femme de 100 ans hospitalisée a...   \n",
      "\n",
      "                                          description  \n",
      "0   La fédération internationale de tennis de tabl...  \n",
      "1   Entre stages d’entraînement et compétitions, l...  \n",
      "2   Vainqueur pour la première fois de sa carrière...  \n",
      "3   Félix et Alexis Lebrun étaient de passage ce j...  \n",
      "4   Martin Namias, connu sous son nom de drag-quee...  \n",
      "5   La flamme olympique traversera Le Mont-Saint-M...  \n",
      "6   L’équipe de France, composée de douze lutteurs...  \n",
      "7   L’ex-international français, seul buteur lors ...  \n",
      "8   Ce jeudi 9 mai, c’est le début du relais de la...  \n",
      "9   L’accident s’est produit vers 18h30, samedi, s...  \n",
      "10  Une enquête a été ouverte après l’agression, l...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e7fbb-bffb-4eca-bf8d-e3df665f51d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
